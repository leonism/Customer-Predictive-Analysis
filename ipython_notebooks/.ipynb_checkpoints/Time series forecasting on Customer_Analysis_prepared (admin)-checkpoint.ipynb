{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forecasting of time series"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup of libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook uses several libraries for handling of Time Series data which are not natively provided as part of the DSS R setup script:\n",
    "\n",
    "* ```forecast```\n",
    "* ```zoo```\n",
    "* ```timeDate```\n",
    "\n",
    "You can either manually install these packages or uncomment the following line to install the packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "install.packages(c(\"forecast\", \"zoo\", \"timeDate\"), repos=\"https://cloud.r-project.org/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required packages\n",
    "library(dataiku)\n",
    "library(forecast)\n",
    "library(data.table)\n",
    "library(zoo)\n",
    "library(timeDate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fist step in the analysis is to load the analysis containing the time series data.\n",
    "\n",
    "Note that this forecast notebook requires the time series data to be a valid DSS date.\n",
    "Since loading data as R dataframe requires a fair amount of RAM, we only load the first 100'000 rows of the dataset. Feel free to change that number in the following cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df <- dkuReadDataset(\"Customer_Analysis_prepared\", samplingMethod=\"head\", nbRows=100000)\n",
    "\n",
    "# The various analysis methods that we will use are not resilient to NA values, so drop them right away\n",
    "df <- na.omit(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's preview a bit of our data\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create table with the initial data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have read the dataset, let's create a \"raw\" table of data, keeping only the \"time\" and \"data\" columns.\n",
    "\n",
    "We assume that:\n",
    " * the date column is the first one\n",
    " * the values column is the second one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_series <- NULL\n",
    "time_series$time_column <- df[,c(1)]\n",
    "time_series$series_column <- df[,c(2)]\n",
    "\n",
    "print(paste(\"Using time column: \", names(df)[1]))\n",
    "print(paste(\"Using value column: \", names(df)[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want to use other columns that these ones, uncomment the following lines\n",
    "\n",
    "# time_series$time_column <- mydataset$my_date_column\n",
    "# time_series$series_column <- mydataset$my_time_series_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We parse the time column as a date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "time_series$time_column <- as.Date(time_series$time_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If your data has a granularity less than the day, you must first it average it by day using this\n",
    "\n",
    "#time_column <- time_series$time_column\n",
    "#series_column <- time_series$series_column\n",
    "#\n",
    "#x = aggregate(series_column ~ time_column, FUN=mean)\n",
    "#time_series$time_column <- as.Date(x$time_column)\n",
    "#time_series$series_column <- x$series_column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the \"raw\" time series. At this point, it might contain holes or irregular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot(time_series$time_column, time_series$series_column, type=\"o\", xlab=\"Time\", ylab=\"Value\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpolation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we can go into more details, we need to make sure that our time series is \"regular\", ie that there are no holes or \"extraneous data\".\n",
    "\n",
    "The first step is to remove holes by:\n",
    "* generating a continuous series between the first and last dates\n",
    "* joining the original data with this continuous series\n",
    "* using a linear interpolation to fill missing data\n",
    "\n",
    "You'll need to select the interpolation granularity, ie the time range that we'll standardize on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We interpolate data day by day\n",
    "# You have a choice of different sampling frequencies \"day\", \"week\", \"month\", \"quarter\" or \"year\"\n",
    "\n",
    "INTERPOLATION_GRANULARITY <- \"day\"\n",
    "\n",
    "alldates <- data.table(seq.Date(min(time_series$time_column), max(time_series$time_column), by=INTERPOLATION_GRANULARITY))\n",
    "\n",
    "alldates$time_column <- alldates$V1\n",
    "\n",
    "# We create a table dt containing the resampled time column\n",
    "dt <- merge(time_series, alldates, by='time_column', all=TRUE)\n",
    "dt$V1 <- NULL\n",
    "\n",
    "# We add to dt the time series interpolated for the new sampling frequency\n",
    "dt$series_column <- na.approx(dt$series_column, x = dt$time_column, na.rm = TRUE) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Let's plot the interpolated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(dt$time_column, dt$series_column, type=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing\n",
    "\n",
    "Now that we have regular data, we could also choose to \"smooth\" the time series (for example, to a month granularity).\n",
    "    \n",
    "Uncomment the following two cells to smooth by month. Note that you'll need to change the TS_FREQUENCY variable later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SMOOOTHING_GRANULARITY <- \"month\"\n",
    "#\n",
    "#alldates_smooth <- data.table(seq.Date(min(dt$time_column), max(dt$time_column), by=SMOOOTHING_GRANULARITY))\n",
    "#\n",
    "#alldates_smooth$time_column <- alldates_smooth$V1\n",
    "#\n",
    "## We create a table dt containing the resampled time column\n",
    "#dt <- merge(dt, alldates_smooth, by='time_column', all=FALSE)\n",
    "#dt$V1 <- NULL\n",
    "#\n",
    "## We add to dt the time series interpolated for the new sampling frequency\n",
    "#dt$series_column <- na.approx(dt$series_column, x = dt$time_column, na.rm = TRUE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the smoothed time series\n",
    "#plot(dt$time_column, dt$series_column, type=\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the TS object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Until now, our data is still specified as two series:\n",
    "* One series of timestamps\n",
    "* One series of values\n",
    "\n",
    "For R forecasting models, we need a \"ts\" object which combines both information.\n",
    "\n",
    "The \"ts\" object has a notion of \"time period\", which is used by all models that try to handle the seasonality.\n",
    "Here, we are assuming a yearly seasonality (and, as seen previously, a daily time series).\n",
    "\n",
    "For example, if your data is actually a monthly time series (or you smoothed by month earlier), use frequency=12 and use the day in month as second argument to \"start\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "beg_date_year = as.numeric(format(min(dt$time_column), \"%Y\"))\n",
    "beg_date_day_in_year = as.numeric(format(min(dt$time_column), \"%j\"))\n",
    "\n",
    "TS_FREQUENCY <- 365\n",
    "\n",
    "tsdata = ts(dt$series_column, start=c(beg_date_year, beg_date_day_in_year), frequency=TS_FREQUENCY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(tsdata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's  set the time period on which we'll predict. We default to 400 (assuming a day time series). You should reduce this if you are using a monthly (or other) time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FORECAST_PERIOD <- 400"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seasonality decomposition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before actually forecasting, we can decompose the time series into the three main components:\n",
    "\n",
    "* Trend: the long-term evolution of the time series\n",
    "* Seasonality: the reproducible variation within each time period (as previously defined)\n",
    "* Random: unpredictable variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "decomposition <- decompose(tsdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(decomposition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forecasting with ARIMA model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ARIMA models are powerful forecasting models, see the wikipedia page for a great introduction:\n",
    "https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average\n",
    "\n",
    "Here, we use \"auto.arima\", which automatically selects the best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_aa = auto.arima(tsdata)\n",
    "summary(model_aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the forecasted data (together with error bars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_aa = forecast(model_aa, h=FORECAST_PERIOD)\n",
    "plot(forecast_aa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ETS Model\n",
    "\n",
    "The simple ARIMA model does not directly take the seasonality into account.\n",
    "\n",
    "Error/Trend/Seasonality models extract recurring sequences (Seasonality), global tendancy (Trend) and remaining noise (Error) and use these for forecasting.\n",
    "\n",
    "For each of these the forecast model will choose if each component is present or not.\n",
    "\"N\"=none, \"A\"=additive, \"M\"=multiplicative\n",
    "\n",
    "http://www.inside-r.org/packages/cran/forecast/docs/ets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETS model can only handle frequency < 24 . For frequency > 24, we switch to STLF model\n",
    "if (TS_FREQUENCY > 24) {\n",
    "    model_ets = stlf(tsdata)\n",
    "} else {\n",
    "    model_ets = ets(tsdata)\n",
    "}\n",
    "summary(model_ets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_ets = forecast(model_ets, h=FORECAST_PERIOD)\n",
    "plot(forecast_ets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TBATS model\n",
    "Exponential smoothing state space model with Box-Cox transformation, ARMA errors, Trend and Seasonal components\n",
    "\n",
    "http://www.inside-r.org/packages/cran/forecast/docs/tbats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_tbats = tbats(tsdata)\n",
    "model_tbats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot how the TBATS model decomposed our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(model_tbats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And plot the actual forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "forecast_tbats = forecast(model_tbats, h=FORECAST_PERIOD)\n",
    "plot(forecast_tbats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing the models\n",
    "\n",
    "We use Akaike's information criterion to compare models\n",
    "\n",
    "Lower is better, close values mean models should be further compared\n",
    "\n",
    "https://en.wikipedia.org/wiki/Akaike_information_criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note: if the ETS model was switched to STLF, the AIC is not available.\n",
    "\n",
    "aics = c(Auto.Arima = model_aa$aic, \n",
    "         ETS = model_ets$aic, \n",
    "         TBATS = model_tbats$AIC)\n",
    "barplot(aics, ylab=\"AIC\", main=\"Model Comparison\", col=\"light blue\")"
   ]
  }
 ],
 "metadata": {
  "analyzedDataset": "Customer_Analysis_prepared",
  "creator": "admin",
  "customFields": {},
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.2.4"
  },
  "tags": [],
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
